{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd90303-80d8-4e5a-b46e-12e1d482c210",
   "metadata": {},
   "source": [
    "# Train and evaluate graphs\n",
    "\n",
    "We can use the pytorch geometric library to make a graph model that can perform classification on different nodes in the graph. [link](https://pytorch-geometric.readthedocs.io/en/latest/)\n",
    "\n",
    "The graph created is the same as the one described in the paper of David P. et al [link](https://arxiv.org/pdf/2107.14756.pdf). We work with the pytorch geometric library to have acess to more recent algorithms that run on graphs.\n",
    "\n",
    "The graph contains two different node types. One node for each ip corresponding to a device and a node for each connection between ip's. Graphs with multiple node types are called heterogenous graphs. \n",
    "\n",
    "We use a transformer based graph neural network designed for heterogenous graphs and implemented in the pytorch geometric library, more details can be found in this paper\n",
    "[link](https://arxiv.org/abs/2003.01332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e1b4e73-f02f-4304-9f0d-6a7e55b074b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/train/week1_prep_train.pkl','rb') as f:\n",
    "    df_train = pickle.load(f)\n",
    "\n",
    "with open('data/eval/week1_prep_val.pkl','rb') as f:\n",
    "    df_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a2060-ad2e-4e1a-9b65-2ecaed5fd23f",
   "metadata": {},
   "source": [
    "We define a class to convert the tabular data to graphs. For each node of type 'ip' corresponding to a device we add a feature based on the ip-adress. For each subnet in the network we create a column and convert ip adresses to a category, this can be seen in the function `encode_ip`.\n",
    "\n",
    "The nodes of type 'connection' contain a number of connection type features defined in the constructor of the class, see `self.conn_feat`. Each connection node also contains a label see `self.labels_cols_oh`.\n",
    "\n",
    "This way we can train an algorithm to classify the connection nodes that also use information from the structure of the graph and ip nodes. Such a graph is created in pieces for example of 200 rows of our tabular dataset, each row contains information about a connection between two devices. In this way we create a snapshot of the network. This is done in the function `process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ccf68a0-b5c1-47ea-9d4d-5320a4df5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zelf grafen aanmaken per 200 connecties\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "class CICdata():\n",
    "    def __init__(self, path_data):\n",
    "        f = open(path_data,'rb')\n",
    "        self.df = pickle.load(f)\n",
    "        self.conn_feat = ['Duration', 'Packets', 'Bytes', 'Proto_ICMP ', 'Proto_IGMP ','Proto_TCP  ', 'Proto_UDP  ','flag_A', 'flag_P', 'flag_R', 'flag_S','flag_F', 'Tos_0', 'Tos_16', 'Tos_32', 'Tos_192']\n",
    "        self.label_cols_oh = ['attack_benign','attack_bruteForce', 'attack_dos', 'attack_pingScan', 'attack_portScan']\n",
    "        \n",
    "        \n",
    "    def make_ip_map(self, data):\n",
    "        unique_ip = np.unique(np.append(data['Src IP Addr'].to_numpy(), \n",
    "                                        data['Dst IP Addr'].to_numpy()))\n",
    "        return {ip:idx for idx, ip in enumerate(unique_ip)}\n",
    "    \n",
    "    def encode_ip(self, value):\n",
    "        temp = [0]*10\n",
    "        if value == '192.168.100.6': #internal web server\n",
    "            temp[0] = 1.0\n",
    "        elif value == '192.168.100.5': #internal file server\n",
    "            temp[1] = 1.0\n",
    "        elif value == '192.168.100.4': #internal mail server\n",
    "            temp[2] = 1.0\n",
    "        elif value == '192.168.100.3': #internal backup server\n",
    "            temp[3] = 1.0\n",
    "        elif value[:11] == '192.168.100': #server subnet\n",
    "            temp[4] = 1.0\n",
    "        elif value[:11] == '192.168.200': #management subnet\n",
    "            temp[5] = 1.0\n",
    "        elif value[:11] == '192.168.210': #office subnet\n",
    "            temp[6] = 1.0\n",
    "        elif value[:11] == '192.168.220': #developer subnet\n",
    "            temp[7] = 1.0\n",
    "        elif value[5:6]=='_': #public ip\n",
    "            temp[8] = 1.0\n",
    "        elif value in ['0.0.0.0', '255.255.255.255']: #local ip\n",
    "            temp[9] = 1.0\n",
    "\n",
    "        return temp\n",
    "    \n",
    "    def get_ip_feat(self, ip_map):\n",
    "        ip_data = []\n",
    "        for ip, idx in ip_map.items():\n",
    "            ip_data.append(self.encode_ip(ip))\n",
    "        \n",
    "        return torch.tensor(ip_data).float()\n",
    "                \n",
    "    def make_edges(self, data, ip_map):\n",
    "        src = []\n",
    "        dst = []\n",
    "        count = 0\n",
    "        for _, row in data.iterrows():\n",
    "            #source ip to connection\n",
    "            src.append(ip_map[row['Src IP Addr']])\n",
    "            dst.append(count)\n",
    "\n",
    "            #destination ip to connection\n",
    "            src.append(ip_map[row['Dst IP Addr']])\n",
    "            dst.append(count)\n",
    "            count +=1\n",
    "\n",
    "        return torch.tensor([src, dst]), torch.tensor([dst, src])\n",
    "\n",
    "    def get_info_conn(self, data, cols):\n",
    "        return torch.tensor(data[cols].values)\n",
    "                \n",
    "    def process(self, n_rows=200):\n",
    "        x_conn = self.get_info_conn(self.df, self.conn_feat)\n",
    "        y = self.get_info_conn(self.df, self.label_cols_oh)\n",
    "        data_list = []\n",
    "        for i in tqdm(range(1, (len(self.df)//n_rows)+1), desc='processing'):\n",
    "            start_idx = (i-1)*n_rows\n",
    "            end_idx = i*n_rows\n",
    "            sample = self.df[start_idx:end_idx]\n",
    "            ip_map = self.make_ip_map(sample)\n",
    "            ip_to_conn, conn_to_ip = self.make_edges(sample, ip_map)\n",
    "            data = HeteroData()\n",
    "            data['ip'].x = self.get_ip_feat(ip_map) #encode ip's from the map\n",
    "            data['connection'].x = x_conn[start_idx:end_idx].float()\n",
    "            data['connection'].y = y[start_idx:end_idx]\n",
    "            data['ip','connection'].edge_index = ip_to_conn\n",
    "            data['connection','ip'].edge_index = conn_to_ip\n",
    "            data_list.append(data)\n",
    "        \n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba0512ab-14d7-420e-897c-4b79e9433c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cic_data = CICdata('data/train/week1_prep_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3dc1b-7a17-4330-80f2-7e5525625942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing:  88%|████████▊ | 9324/10559 [01:09<00:09, 135.05it/s]"
     ]
    }
   ],
   "source": [
    "data = cic_data.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043d33e-2883-4751-ab4c-e67c01017e42",
   "metadata": {},
   "source": [
    "We can display the types of nodes in our dataset along with the edges.\n",
    "* two node types: 'ip' and 'connection'.\n",
    "* two edge types: from ip to connection node or from connection to ip node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457bfcb-26f0-4a86-9df5-2d46eb610f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data[0].node_types)\n",
    "print(data[0].metadata())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb5a3e-3219-4894-938d-2ac17c47134d",
   "metadata": {},
   "source": [
    "A heterogenous graph transformer model can be easily made by using built-in classes. Some hyperparameters can be chosen such as the number of heads, hidden channels and number of layers.\n",
    "\n",
    "The number of out channels is always the number of unique label values (5 in the example dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532b0bd-ed72-4f29-88c3-4541b65d4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "\n",
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, data_graph, hidden_channels, out_channels, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in data_graph.node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
    "\n",
    "        print(self.lin_dict)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data_graph.metadata(),\n",
    "                           num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):        \n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        return self.lin(x_dict['connection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e76484-6ac3-4818-b04d-77720a3951d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = HGT(data_graph= data[0], hidden_channels=64, out_channels=5,\n",
    "            num_heads=4, num_layers=2)\n",
    "# Initialize lazy module, still on cpu\n",
    "with torch.no_grad():\n",
    "    out = model(data[0].x_dict, data[0].edge_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00daa5d-9c27-4996-80b1-04cb2d143be0",
   "metadata": {},
   "source": [
    "The algorithm is trained with boilerplate pytorch code. The number of epochs and batch size can be adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e173f9c-5a82-4112-bad5-93d08269dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader, DataListLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#hyperparams\n",
    "EPOCHS = 20\n",
    "batch_size = 64\n",
    "\n",
    "optimizer = Adam(model.parameters())\n",
    "train_loader = DataLoader(data, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_examples = total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            batch.to(device)\n",
    "            out = model(batch.x_dict, batch.edge_index_dict)\n",
    "            #print(batch['connection'].y, batch['connection'].y.size())\n",
    "            # print(out, out.size())\n",
    "            loss = F.cross_entropy(out, batch['connection'].y.float())\n",
    "            #loss = focal_loss(out, batch['connection'].y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_examples += 64\n",
    "            total_loss += float(loss) * 64\n",
    "            \n",
    "        tqdm.write('EPOCH '+str(epoch)+' loss: '+ str(total_loss/total_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0837c27-7270-4411-b490-41b752bcba84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630a65b-e485-4786-a51f-c624c7c11d58",
   "metadata": {},
   "source": [
    "The tabular data for evaluation is converted into graphs and predictions are made with the now trained algorithm. Notice labels are extracted from the `connection` nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7635f94-c714-4f2c-9c04-bc93d952babd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████| 2639/2639 [00:19<00:00, 133.83it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "cic_val = CICdata('data/eval/week1_prep_val.pkl')\n",
    "data_val = cic_val.process()\n",
    "\n",
    "#save as pickle file\n",
    "with open('graph_val.pkl', 'wb') as f:\n",
    "    pickle.dump(data_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe6330-e468-4347-a599-0d3e3dc9446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "count=0\n",
    "preds = []\n",
    "labels = []\n",
    "for graph in tqdm(data_val):\n",
    "    graph.to(device)\n",
    "    preds.append(model(graph.x_dict, graph.edge_index_dict).argmax(dim=1))\n",
    "    labels.append(graph['connection'].y.argmax(dim=1))\n",
    "\n",
    "preds = torch.cat(preds)\n",
    "labels = torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a638397-5bf7-404c-9ac8-2301cad3c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precise calculation of accuracy\n",
    "correct = (preds == labels).sum()\n",
    "acc = correct / len(preds)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2505821-427a-46bb-a9ed-e98f6c8b8b0e",
   "metadata": {},
   "source": [
    "The label values were one-hot encoded. The numbers [0, 1, 2, 3, 4] correspond to the different classes. We can convert these back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82abfa0-40b5-4b8b-9191-5c49dc6939ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(preds.cpu(), labels.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df06187-42e5-4cb5-854d-65ae5f44bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "map_class = {'0':'benign', '1':'bruteforce', '2':'dos', '3':'pingscan', '4':'portscan'}\n",
    "cr_df = pd.DataFrame(classification_report(preds.cpu(), labels.cpu(), output_dict=True)).transpose()\n",
    "temp = cr_df.index[:5].map(map_class).append(cr_df.index[5:])\n",
    "cr_df.index = temp\n",
    "cr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196772a8-90d1-474e-babc-7029e22980e7",
   "metadata": {},
   "source": [
    "The results clearly show the `bruteforce` and `pingscan` attacks are much harder to detect. They also occur much less in the dataset according to the support column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9370ccca-dd57-4a13-8083-555578eca0c6",
   "metadata": {},
   "source": [
    "### Visualization & explanation\n",
    "\n",
    "We can extract some information of the graphs to visualize connections in the network and connections predicted as part of an attack.\n",
    "\n",
    "We can also list the properties of connections that are predicted as part of an attack and related devices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3eb598-3c0c-4174-93f3-7d126f18b5cc",
   "metadata": {},
   "source": [
    "Each graph in our dataset contains 200 connections default we can take a sub-sample of the graph by looking at the neighbours of ip-type nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c4c20-86e9-4f99-aab2-6b1bbcfb5c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('graph_val.pkl', 'rb') as f:\n",
    "    data_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6170c5-df01-4d56-b4d8-a0651d6a8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "#indexes in dataset for different scenario's\n",
    "examples = {'portscan':2, 'bruteforce':1222, 'dos':2000, 'pingscan':1467}\n",
    "\n",
    "g = data_val[examples['portscan']]\n",
    "\n",
    "nloader = NeighborLoader(\n",
    "    data=g,\n",
    "    # Sample all neighbors for each node and each edge type for 2 iterations:\n",
    "    num_neighbors={('ip', 'to', 'connection'): [-1]*2 , ('connection', 'to', 'ip'): [-1]*2},\n",
    "    input_nodes=('ip'),\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "sample = next(iter(nloader)).to('cpu')\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f4bbf-d2ee-4f7b-ba22-824d51713387",
   "metadata": {},
   "source": [
    "We can convert a HeteroData object to a networkx object to visualize this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f1353-a785-44e1-ab4a-af8aab2aa3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "def to_networkx_graph(ptgraph):\n",
    "    G = nx.Graph()\n",
    "    #add ip nodes\n",
    "    for i in range(ptgraph['ip'].x.shape[0]):\n",
    "        G.add_node('ip_'+str(i), ip=sample['ip'].x[i])\n",
    "    \n",
    "    for i in range(ptgraph['connection'].x.shape[0]):\n",
    "        G.add_node('conn_'+str(i), x=ptgraph['connection'].x[i], y=ptgraph['connection'].y[i].argmax().item())\n",
    "        \n",
    "    for ip_idx, conn_idx in ptgraph['ip','connection'].edge_index.T:\n",
    "        G.add_edge('ip_'+str(ip_idx.item()), 'conn_'+str(conn_idx.item()))\n",
    "    \n",
    "    for conn_idx, ip_idx in ptgraph['connection','ip'].edge_index.T:\n",
    "        G.add_edge('conn_'+str(conn_idx.item()), 'ip_'+str(ip_idx.item()))\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2603b-16f0-439a-b52e-bdf921ccff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx_graph(sample)\n",
    "print(len(G.nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67dc018-ff1d-4a30-9370-6c5340244115",
   "metadata": {},
   "source": [
    "Sample of the network is visualised below with different icons for:\n",
    "- Benign connections or malicious connections.\n",
    "- Internal devices or servers\n",
    "- External devices\n",
    "\n",
    "This way affected devices by attacks can be visualized and also the devices receiving the most traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dad985-1679-4e8f-ba35-e15e57bd6f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cdbdc6-79ea-473f-90d9-8172f16d226c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_network(G, layout='kamada-kawai', path_fig=None, path_expl=None):\n",
    "    #filter connections based on benign or malicious\n",
    "    #filter devices based on internal devices, internal servers or external devices.\n",
    "    conns = list(filter(lambda x: x[0]=='c', list(G.nodes)))\n",
    "    ips = list(filter(lambda x: x[0]=='i', list(G.nodes)))\n",
    "    ip_server = list(filter(lambda x: G.nodes[x]['ip'].argmax() in [0,1,2,3,4] , ips))\n",
    "    ip_device = list(filter(lambda x: G.nodes[x]['ip'].argmax() in [5,6,7,9] , ips))\n",
    "    ip_external = list(filter(lambda x: G.nodes[x]['ip'].argmax()==8, ips))\n",
    "\n",
    "    conns_attack = list(filter(lambda x: G.nodes[x]['y']!=0, conns))\n",
    "    conns_normal = list(filter(lambda x: G.nodes[x]['y']==0, conns))\n",
    "\n",
    "    #### EXPLANATION\n",
    "    labels = ['attack_benign','attack_bruteForce', 'attack_dos', 'attack_pingScan', 'attack_portScan']\n",
    "    subnets = ['the web server','the file server','the mail server','the backup server', 'the server subnet', \n",
    "           'the management subnet', 'the office subnet', 'the developer subnet', 'an external ip', 'a local ip']\n",
    "    label_map = {idx:label for idx, label in enumerate(labels)}\n",
    "    subnet_map = {idx:subnet for idx, subnet in enumerate(subnets)}\n",
    "    \n",
    "    ip_attack = {}\n",
    "    for c in conns_attack:\n",
    "        key = []\n",
    "        for t in G.edges(c):\n",
    "            key.append(t[1])\n",
    "        key.sort()\n",
    "        key = key+[label_map[G.nodes[c]['y']]]\n",
    "\n",
    "        if tuple(key) in ip_attack.keys():\n",
    "            ip_attack[tuple(key)] = ip_attack[tuple(key)]+[c]\n",
    "        else:\n",
    "            ip_attack[tuple(key)]=[c]\n",
    "    \n",
    "    explanation=''\n",
    "    for key in ip_attack.keys():\n",
    "        device_a = subnet_map[G.nodes[key[0]]['ip'].argmax().item()]\n",
    "        device_b = subnet_map[G.nodes[key[1]]['ip'].argmax().item()]\n",
    "        label_descr = label_map[G.nodes[ip_attack[key][0]]['y']]\n",
    "        explanation += f'{len(ip_attack[key])} connections between {device_a} ({key[0]}) and {device_b} ({key[1]}) consists of {label_descr}\\n'\n",
    "    \n",
    "    if path_expl:\n",
    "            with open(path_expl, 'w') as f:\n",
    "                f.write(explanation)\n",
    "    \n",
    "    print(explanation)\n",
    "            \n",
    "    #### PLOT\n",
    "    #good layouts kamada_kawai, spring\n",
    "    if layout=='spring':\n",
    "        pos = nx.spring_layout(G)\n",
    "    elif layout=='kamada-kawai':\n",
    "        pos = nx.kamada_kawai_layout(G) \n",
    "    else:\n",
    "        print('\\n choose one of spring or kamada-kawai for layout\\n')\n",
    "    \n",
    "    #draw edges and different nodes\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    nx.draw_networkx_edges(G, pos=pos, arrows=True,  min_source_margin=10, min_target_margin=10)\n",
    "    nx.draw_networkx_nodes(G, pos=pos, nodelist=conns_normal, node_color=\"tab:grey\", alpha=0.5, node_size=30,\n",
    "                          label='Benign connections')\n",
    "    nx.draw_networkx_nodes(G, pos=pos, nodelist=conns_attack, node_shape=markers['malicious'], node_color=\"tab:red\",\n",
    "                          node_size=600, label='Malicious connections')\n",
    "    nx.draw_networkx_nodes(G, pos=pos, nodelist=ip_server, node_shape=markers['server'], node_color=\"tab:green\",\n",
    "                          node_size=1000, label='Server')\n",
    "    nx.draw_networkx_nodes(G, pos=pos, nodelist=ip_device, node_shape=markers['pc'], node_color=\"tab:blue\",\n",
    "                          node_size=500, label='Device')\n",
    "    nx.draw_networkx_nodes(G, pos=pos, nodelist=ip_external, node_shape=markers['connection'], node_color=\"tab:blue\",\n",
    "                          node_size=350, label='External ip')\n",
    "    \n",
    "    #add legend with all nodes\n",
    "    prop = {\"weight\":\"bold\", \"size\":\"xx-large\"}\n",
    "    plt.legend(loc=\"upper right\", fancybox=True, shadow=True,  \n",
    "               fontsize=\"xx-large\",\n",
    "               title_fontproperties = prop,\n",
    "               title=\"Node types\")\n",
    "\n",
    "    #provide explanation\n",
    "    \n",
    "    if path_fig:\n",
    "        plt.savefig(output_path, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f3881-815f-4086-82f8-1c07296943e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_network(G, path_expl='explanation.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af25a3-de3c-40e9-9b1a-223948cbaf56",
   "metadata": {},
   "source": [
    "We can also extract the malicious connections and the devices they talked to for an overview of attacks executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f8bab-956c-4490-8a08-9ee403600223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_attacks(G, output_path=None):\n",
    "    conns = list(filter(lambda x: x[0]=='c', list(G.nodes)))\n",
    "    conns_attack = list(filter(lambda x: G.nodes[x]['y']!=0, conns))\n",
    "    \n",
    "    labels = ['attack_benign','attack_bruteForce', 'attack_dos', 'attack_pingScan', 'attack_portScan']\n",
    "    subnets = ['the web server','the file server','the mail server','the backup server', 'the server subnet', \n",
    "           'the management subnet', 'the office subnet', 'the developer subnet', 'an external ip', 'a local ip']\n",
    "    label_map = {idx:label for idx, label in enumerate(labels)}\n",
    "    subnet_map = {idx:subnet for idx, subnet in enumerate(subnets)}\n",
    "    \n",
    "    ip_attack = {}\n",
    "    for c in conns_attack:\n",
    "        key = []\n",
    "        for t in G.edges(c):\n",
    "            key.append(t[1])\n",
    "        key.sort()\n",
    "        key = key+[label_map[G.nodes[c]['y']]]\n",
    "\n",
    "        if tuple(key) in ip_attack.keys():\n",
    "            ip_attack[tuple(key)] = ip_attack[tuple(key)]+[c]\n",
    "        else:\n",
    "            ip_attack[tuple(key)]=[c]\n",
    "    \n",
    "    for key in ip_attack.keys():\n",
    "        device_a = subnet_map[G.nodes[key[0]]['ip'].argmax().item()]\n",
    "        device_b = subnet_map[G.nodes[key[1]]['ip'].argmax().item()]\n",
    "        label_descr = label_map[G.nodes[ip_attack[key][0]]['y']]\n",
    "        explanation = f'{len(ip_attack[key])} connections between {device_a} ({key[0]}) and {device_b} ({key[1]}) consists of {label_descr}\\n'\n",
    "        \n",
    "        if output_path:\n",
    "            with open(output_path, 'a') as f:\n",
    "                f.write(explanation)\n",
    "        else:\n",
    "            print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec72d486-bed2-4b2e-ac94-7edc098f08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_attacks(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7111118f-1733-40a5-b33e-c47441b413c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#or save in file\n",
    "describe_attacks(G, 'explanation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220e43e-66ee-4c28-980e-090bcbe1ef5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph env",
   "language": "python",
   "name": "env_gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
